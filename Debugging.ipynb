{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAA88jsqbNNgjebDIf1lVA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SampMark/Computational-Thinking/blob/main/Debugging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercício de Debugging**\n",
        "\n",
        "O exercício proposto no curso **MITx 6.86x**: *Machine Learning with Python-From Linear Models to Deep Learning* tem por objetivo contribuir para o desenvolvimento de habilidades de **debugging** (depuração) em Python, especificamente usando o **pdb** (Python Debugger).  \n",
        "\n",
        "Em suma, o foco é corrigir um código com bugs e garantir que funcione dentro do esperado. Neste caso, vamos trabalhar aqui, com sucessivas versões do código, até resolver o bug.\n",
        "\n",
        "**Contexto do Exercício**\n",
        "\n",
        "O exercício propõe a depuração de uma função chamada `get_sum_metrics`, que recebe recebe dois argumentos:\n",
        "\n",
        "* `prediction`: Uma previsão (por exemplo, um valor numérico ou uma classificação).\n",
        "\n",
        "* `metrics`: uma lista de métricas (funções) que devem ser aplicadas à previsão. Cada métrica é uma função que deve ser aplicada à predição como entrada e retornar um valor.\n",
        "\n",
        "O objetivo da função é somar os resultados dessas métricas aplicadas à predição, juntamente com três métricas padrão que adicionam os valores 0, 1 e 2 à predição.\n",
        "\n",
        "* **Natureza das métricas**: as métricas são funções e não números, então a implementação deve garantir que elas sejam chamadas corretamente.\n",
        "\n",
        "* **Adição de valores padrão**: além das métricas fornecidas, a função também deve adicionar `prediction + 0`, `prediction + 1` e `prediction + 2` ao resultado final."
      ],
      "metadata": {
        "id": "cZlzRiT9CbXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Possíveis problemas na versão inical do código**\n",
        "\n",
        "---\n",
        "\n",
        "Os seguintes problemas podem estar presentes no código original abaixo:\n",
        "\n",
        "* **Chamadas incorretas das funções na lista de métricas**: Se a implementação não chamar as funções corretamente, ocorrerá um erro.\n",
        "* **Somar funções em vez de valores numéricos**: se as funções na lista não forem chamadas antes da soma, a operação pode falhar.\n",
        "* **Não inclusão das métricas padrão**: esquecimento de incluir as métricas padrão (0, 1 e 2).\n",
        "* **Falta de tratamento de erros**: Se alguma métrica falhar ao processar a predição, o programa pode quebrar."
      ],
      "metadata": {
        "id": "yvIgRhuc89uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sum_metrics(predictions, metrics=[]):\n",
        "    for i in range(3):\n",
        "        metrics.append(lambda x: x + i)\n",
        "\n",
        "    sum_metrics = 0\n",
        "    for metric in metrics:\n",
        "        sum_metrics += metric(predictions)\n",
        "\n",
        "    return sum_metrics\n",
        "\n",
        "print(get_sum_metrics(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_jm971182xp",
        "outputId": "45dcf847-6657-4988-9612-0e4440953d69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Debugging test** ❌"
      ],
      "metadata": {
        "id": "uhNgMxZe8Rmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sum_metrics(prediction, metrics):\n",
        "    for i in range(3):\n",
        "        metrics.append((lambda i: lambda x: x + i)(i))\n",
        "\n",
        "    sum_metrics = 0\n",
        "    for metric in metrics:\n",
        "        sum_metrics += metric(prediction)\n",
        "\n",
        "    return sum_metrics\n",
        "\n",
        "print(get_sum_metrics(0, []))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_WLc91h8O5a",
        "outputId": "86c5c4f6-a13e-4fa2-e59b-70b8064031cc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Debugging test** ❌"
      ],
      "metadata": {
        "id": "PckaX9hH8fHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sum_metrics(predictions, metrics=[]):\n",
        "    for i in range(3):\n",
        "        metrics.append(lambda x, i=i: x + i)  # Captura o valor de i\n",
        "\n",
        "    sum_metrics = 0\n",
        "    for metric in metrics:\n",
        "        sum_metrics += metric(predictions)\n",
        "\n",
        "    return sum_metrics\n",
        "\n",
        "print(get_sum_metrics(0, []))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S4mJY3wz_zq",
        "outputId": "7ba6c7a2-49f7-42d6-fdbd-537e8fe605ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Debugging test** ❌"
      ],
      "metadata": {
        "id": "XlqE9hhn-23F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sum_metrics(predictions, metrics=None):\n",
        "    if metrics is None:\n",
        "        metrics = []\n",
        "\n",
        "    for i in range(3):\n",
        "        metrics.append(lambda x, i=i: x + i)  # Captura o valor correto de i\n",
        "\n",
        "    sum_metrics = 0\n",
        "    for metric in metrics:\n",
        "        sum_metrics += metric(predictions)\n",
        "        print(sum_metrics)  # Exibir resultado intermediário como no enunciado\n",
        "\n",
        "    return sum_metrics\n",
        "\n",
        "print(get_sum_metrics(0, []))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJp80p2W-wpF",
        "outputId": "97fafe96-17dd-45fa-cceb-144c77ef11e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "3\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_get_sum_metrics():\n",
        "    def metric1(x): return x * 2\n",
        "    def metric2(x): return x - 3\n",
        "\n",
        "    predictions = 3\n",
        "    metrics = [metric1, metric2]\n",
        "\n",
        "    print(\"✅Saída esperada:\")\n",
        "    print(\"3\\n6\\n9\\n6\\n11\\n3\\n6\\n9\")\n",
        "\n",
        "    print(\"\\n⚠️Saída obtida:\")\n",
        "    get_sum_metrics(predictions, metrics)\n",
        "\n",
        "test_get_sum_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QD7fWj751Ye",
        "outputId": "dd8c2161-587f-490a-fae0-43d258854218"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅Saída esperada:\n",
            "3\n",
            "6\n",
            "9\n",
            "6\n",
            "11\n",
            "3\n",
            "6\n",
            "9\n",
            "\n",
            "⚠️Saída obtida:\n",
            "6\n",
            "6\n",
            "9\n",
            "13\n",
            "18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Debugging test** Pass! ✅"
      ],
      "metadata": {
        "id": "dkAtbLeX_C-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sum_metrics(predictions, metrics=None):\n",
        "    \"\"\"\n",
        "    Calcula a soma de métricas para uma determinada previsão.\n",
        "\n",
        "    Argumentos:\n",
        "    prediction: O valor da previsão.\n",
        "    metrics: Uma lista de funções métricas para aplicar à previsão. Se None, apenas as métricas padrão serão usadas.\n",
        "\n",
        "    Retorna:\n",
        "    A soma de todas as métricas aplicadas à previsão.\n",
        "    \"\"\"\n",
        "    if metrics is None:\n",
        "        metrics = []\n",
        "\n",
        "    # Adicionar métricas padrão (0, 1, 2)\n",
        "    for i in range(3):\n",
        "        metrics.append((lambda i: lambda x: x + i)(i))\n",
        "\n",
        "    sum_metrics = 0\n",
        "\n",
        "    # Aplicar todas as métricas (personalizadas e padrão)\n",
        "    for metric_func in metrics:\n",
        "        sum_metrics += metric_func(predictions)\n",
        "\n",
        "    return sum_metrics\n",
        "\n",
        "# Exemplo de uso\n",
        "print(get_sum_metrics(0, []))  # Saída esperada: 3 (0 + 1 + 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFFzF74pF-Mq",
        "outputId": "c54f45a5-b873-412a-9158-bf4386132e67"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_get_sum_metrics():\n",
        "    \"\"\"\n",
        "    Testa a função get_sum_metrics com vários casos de teste e verifica se o resultado\n",
        "    corresponde ao \"Correct Output\" esperado.\n",
        "    \"\"\"\n",
        "    # Casos de teste com os resultados esperados\n",
        "    test_cases = [\n",
        "        (0, [], 3),          # prediction=0, metrics=[], expected=3 (0 + 1 + 2)\n",
        "        (1, [], 6),          # prediction=1, metrics=[], expected=6 (1 + 2 + 3)\n",
        "        (2, [], 9),          # prediction=2, metrics=[], expected=9 (2 + 3 + 4)\n",
        "        (3, [lambda x: x * 2], 15),  # prediction=3, metrics=[lambda x: x * 2], expected=15 (6 + 3 + 4 + 5)\n",
        "        (0, [lambda x: x + 10], 33), # prediction=0, metrics=[lambda x: x + 10], expected=33 (10 + 0 + 1 + 2)\n",
        "        (1, [lambda x: x * 3], 12),  # prediction=1, metrics=[lambda x: x * 3], expected=12 (3 + 1 + 2 + 3)\n",
        "        (2, [lambda x: x - 1], 9)    # prediction=2, metrics=[lambda x: x - 1], expected=9 (1 + 2 + 3 + 4)\n",
        "    ]\n",
        "\n",
        "    # Executar os testes\n",
        "    for i, (prediction, metrics, expected) in enumerate(test_cases):\n",
        "        result = get_sum_metrics(prediction, metrics)\n",
        "        if result == expected:\n",
        "            print(f\"Caso de teste {i+1} ✅passou: esperado {expected}, obtido {result}\")\n",
        "        else:\n",
        "            print(f\"Caso de teste {i+1} ❌falhou: esperado {expected}, obtido {result}\")\n",
        "\n",
        "# Executar a função de teste\n",
        "test_get_sum_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsUCMMKmHEsc",
        "outputId": "ccea4247-7fdd-4ea4-9fd9-1ac445d15b6e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caso de teste 1 ✅passou: esperado 3, obtido 3\n",
            "Caso de teste 2 ✅passou: esperado 6, obtido 6\n",
            "Caso de teste 3 ✅passou: esperado 9, obtido 9\n",
            "Caso de teste 4 ❌falhou: esperado 15, obtido 18\n",
            "Caso de teste 5 ❌falhou: esperado 33, obtido 13\n",
            "Caso de teste 6 ❌falhou: esperado 12, obtido 9\n",
            "Caso de teste 7 ❌falhou: esperado 9, obtido 10\n"
          ]
        }
      ]
    }
  ]
}